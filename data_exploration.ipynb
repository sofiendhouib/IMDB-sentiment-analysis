{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis for the IMDB reviews dataset\n",
    "\n",
    "In this notebook, we tackle IMDB reviews sentiment analysis (download link available on the [README file](./README.md)). It consists of 50000 reviews, each associated a positive or negative sentiment. The goal of this notebook is to build a classifier that is available to predict the sentiment given the reviews, with high accuracy.\n",
    "\n",
    "In a first stage, we select a subset of data to work on (e.g 5000 samples, i.e. 10% of the whole dataset). The goal of this step is to experiment with different cleaning strategies, and to perform hyperparameter selection. \n",
    "\n",
    "Then, we will divide the whole dataset into 25000 train samples, and 25000 test samples.\n",
    "    * The train sample is used to train a model with hyperparamters obtained from the cross-validaton procedure on the data subset used previously.\n",
    "    * The test set is used solely for model performance assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries imports\n",
    "\n",
    "Depending on whether the nltk resources needed for data cleaning are present on the machine or not, this notebook cell might take some time to execute depending on the internet speed connection, to download the nltk lacking resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from itertools import chain\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar= True)\n",
    "\n",
    "\n",
    "import utils, postprocess as postproc, preprocess as preproc, tuning\n",
    "from os import path\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a data subset\n",
    "We select a subset of data points, we use half of them for training and the other half for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taran Adarsh a reputed critic praised such a d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I liked Antz, but loved \"A Bug's Life\". The an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This reboot is like a processed McDonald's mea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The working title was: \"Don't Spank Baby\". &lt;br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Taran Adarsh a reputed critic praised such a d...          0\n",
       "1  Worth the entertainment value of a rental, esp...          0\n",
       "2  I liked Antz, but loved \"A Bug's Life\". The an...          1\n",
       "3  This reboot is like a processed McDonald's mea...          0\n",
       "4  The working title was: \"Don't Spank Baby\". <br...          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not path.exists(\"./data/data_raw_sub.csv\"):\n",
    "    df_raw_all = pd.read_csv(\"./data/data_raw.csv\")\n",
    "    df_raw_sub = model_selection.train_test_split(df_raw_all, train_size= 0.1, \n",
    "                                                  stratify = df_raw_all[\"sentiment\"],\n",
    "                                                  random_state= 0)[0]\n",
    "    #df_raw_sub = df_raw\n",
    "    df_raw_sub.to_csv(\"data/data_raw_sub.csv\", index= False)\n",
    "\n",
    "df = pd.read_csv(\"data/data_raw_sub.csv\")\n",
    "df_raw = pd.read_csv(\"data/data_raw.csv\")\n",
    "df[\"sentiment\"] = (df[\"sentiment\"]==\"positive\").values.astype(\"int8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading and cleaning\n",
    "In this part, we perform data cleaning. This is done one time over the whole data sets, and comprises processing steps that do not affect the task at hand (sentiment analysis in this case. ) In other words, these steps are not tunable. Such steps necessarily do not depend on the data distribution, but solely on the example at hand. They include:\n",
    "* Removing html tags\n",
    "* Removing punctuation\n",
    "* Shortening/Removing long spaces and other characters (i.e. underscores)\n",
    "\n",
    "Once the cleaning is done (or if the cleaned file already exists), then a subset of training set is selected, on which most of the experiments to select a model are carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a56f0b79364594b9a874ec91ff4efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taran Adarsh a reputed critic praised such a d...</td>\n",
       "      <td>0</td>\n",
       "      <td>a reputed critic praise such a dubba movie fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, esp...</td>\n",
       "      <td>0</td>\n",
       "      <td>worth the entertainment value of a rental espe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I liked Antz, but loved \"A Bug's Life\". The an...</td>\n",
       "      <td>1</td>\n",
       "      <td>i like but love a animation that be put into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This reboot is like a processed McDonald's mea...</td>\n",
       "      <td>0</td>\n",
       "      <td>this reboot be like a processed meal compare t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The working title was: \"Don't Spank Baby\". &lt;br...</td>\n",
       "      <td>1</td>\n",
       "      <td>the work title be not go on to become a succes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  Taran Adarsh a reputed critic praised such a d...          0   \n",
       "1  Worth the entertainment value of a rental, esp...          0   \n",
       "2  I liked Antz, but loved \"A Bug's Life\". The an...          1   \n",
       "3  This reboot is like a processed McDonald's mea...          0   \n",
       "4  The working title was: \"Don't Spank Baby\". <br...          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  a reputed critic praise such a dubba movie fil...  \n",
       "1  worth the entertainment value of a rental espe...  \n",
       "2  i like but love a animation that be put into t...  \n",
       "3  this reboot be like a processed meal compare t...  \n",
       "4  the work title be not go on to become a succes...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_steps = preproc.clean_steps_before_normalize\n",
    "#print(cleaning_steps)\n",
    "text_processor = partial(preproc.clean_text, check_spell= False, normalize= \"lemmatize\", rm_stop_words= False, \n",
    "                         steps = cleaning_steps)\n",
    "df[\"review_clean\"] = df[\"review\"].parallel_apply(text_processor)\n",
    "#df_cln[\"review\"] = df_raw[\"review\"].progress_apply(text_processor)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fraction do unknown words represent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a3b5396f7d45a88fafe553daaa23a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = []\n",
    "for s in tqdm(df[\"review_clean\"]):\n",
    "    words.extend(s.split())\n",
    "words = set(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.81 % of words are unknown !\n"
     ]
    }
   ],
   "source": [
    "unknown_words = preproc.spell_checker.unknown(words)\n",
    "print(f\"{len(unknown_words)/len(set(words))*100:.2f} % of words are unknown !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu\n",
      "strummer\n",
      "voy\n",
      "guignol\n",
      "flagrante\n",
      "vadim\n",
      "anatomising\n",
      "impresson\n",
      "ballbusting\n",
      "sloow\n",
      "vierde\n",
      "protegee\n",
      "hugo\n",
      "leeze\n",
      "beeg\n",
      "eightiesly\n",
      "reunuin\n",
      "zen\n",
      "za\n",
      "sexploitative\n",
      "represntation\n",
      "unsensationalized\n",
      "dawson\n",
      "riviting\n",
      "cassarole\n",
      "cum\n",
      "imprisonement\n",
      "louise\n",
      "ga\n",
      "cleansweep\n",
      "pooja\n",
      "epiphanous\n",
      "meth\n",
      "tonto\n",
      "bejeebers\n",
      "honoured\n",
      "horts\n",
      "camelot\n",
      "kz\n",
      "pardesi\n"
     ]
    }
   ],
   "source": [
    "for w in list(unknown_words)[:40]:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Whew! What can one say about this bizarre, stupefying mock-u-mentory about '\n",
      " \"Ed Wood's cross-dressing fantasies?? Well, one word that comes to mind is \"\n",
      " 'incoherent! Wood uses raw slabs of innocuous, incidental stock footage, and '\n",
      " 'then builds a \"story\" around them - and what a story!! Wood himself stars as '\n",
      " 'Glen, a regular Joe who just happens to enjoy lounging around in his '\n",
      " \"fiancee's lingerie and sweaters. I think what Wood wanted was a plea for \"\n",
      " 'tolerance for all the Glens of this world by showing that Glen is just like '\n",
      " 'all of us underneath, only in angora. Ummm...ok. But then, we get this very '\n",
      " 'bizarre montage of some horny devil, a chick in bondage, some rude, pointing '\n",
      " 'people, some moore stock footage, and finally an emaciated Bela '\n",
      " 'Lugusi,playing some kind of twisted, invalid Puppetmaster. Lugosi is a howl, '\n",
      " 'spouting out such rubbish as \"Beeevaaare...the beeeg greeeen dragon that '\n",
      " 'seeets at your doorstep: he eeeets leeetle boys, puppydog tails, and beeeeeg '\n",
      " 'snails!\" Um, ok, Bela... :=8/ There is a strange, twisted type of Wood logic '\n",
      " 'going on here. Afterall, he does remind us that \"7 out of 10 men wear hats, '\n",
      " 'and 7 out of 10 men are bald\". Hmmm, must be that '\n",
      " 'alien/cross-dressing/habidashery cowspiracy-thang!! Glen or Glenda stars a '\n",
      " 'plethora (whatever that is...) of reliable Wood schlock-actors, including '\n",
      " 'Lyle Talbot, Delores Fuller, and Timothy Farrell, and Wood manages to coax '\n",
      " 'every bit of wretched, amateurish non-talent out of each one. Everybody by '\n",
      " \"now knows Bela's sad story: by the time Wood used him for this flic, he was \"\n",
      " 'probably jonesing for another fix and needed the moolah, but even for him '\n",
      " \"this is depth heretofore unreached. One of the MooCow's favorite Wood \"\n",
      " 'mooments comes with the stock footage charging buffalo scene - it is sooo '\n",
      " 'loopily demented!! The MooCow says \"Puuuull de schtriiiiings\", and git yer '\n",
      " \"hooves on a copy of Glen or Glenda - you won't believe it! :\\x8d\")\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1282])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_error_source(unk_wrd, col):\n",
    "    inds = np.where(df[\"review_clean\"].apply(lambda s: unk_wrd in s.lower().split()).values)[0]\n",
    "    for i in inds:\n",
    "        pprint.pprint(df[col].iloc[i])\n",
    "        print(\"----\")\n",
    "    return inds\n",
    "\n",
    "print_error_source(\"beeg\", \"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.proper_noun_re.match(\"Asia Argento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following sources of unknown words:\n",
    "* British/American spelling\n",
    "* using adverbs that do not exist in the english language by adding the \"ly\" suffix for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What languages are there ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langdetect\n",
    "# df_raw[\"language\"]= df_raw[\"review\"].parallel_apply(lambda s: langdetect.detect(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.sub(r\"([A-Z][a-z]+ *){2,}|.+ ([A-Z][a-z]+ *)+\", \" \", \"hat is Happening\")\n",
    "re.sub(r\"([A-Z][a-z]+ *){2,}|.+ [A-Z][a-z]+\", \" \", \"hat is Happening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what  did'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"([^\\.])[A-Z][a-z]+\", r\"\\1\", \"what Alex did\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "* [ ] Write tests for every regular expression\n",
    "* Take into account english and american spelling for the spell checker\n",
    "* Examine the languages\n",
    "* Take into account: \n",
    "    * proper nouns of one word: needs better pattern\n",
    "    * the all capitalized text, mixture of capitalized and non capitalized\n",
    "    * The exclamation points\n",
    "    * emoticons\n",
    "    * smileys\n",
    "    * message abbreviations: tldr, lol, lmao etc\n",
    "    * content between quotation marks\n",
    "    * presence of laughs --> standardize to a common laugh ? e.g. replace by \"hhhh\" ? does the length convey some sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.spell_checker.correction(\"hhhhhh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
